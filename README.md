## 📌 Kafka (분산 메시지 큐)
- 다양한 데이터 소스로부터 다량의 데이터를 실시간으로 처리하기 위해 선택했습니다.

- 특히 금융 데이터 같은 실시간 시계열 데이터 처리에는 Kafka의 빠른 처리 속도와 안정성이 적합합니다.

- 3 노드 클러스터 구성을 통해 내결함성(fault-tolerance) 및 가용성(availability)을 높였습니다.

- 각 데이터 소스(주식, 원유, 금)를 별도의 Topic으로 관리하여 순서 보장 및 데이터 처리의 신뢰성을 강화했습니다.

## 📌 Spark Streaming
- Kafka에서 전송된 데이터를 실시간으로 처리하는 스트리밍 엔진으로, 대용량 실시간 데이터 처리에 최적화되어 있습니다.

- 스트리밍 특성상 급격한 데이터 증가에 따른 부하 관리가 중요한데, Spark는 분산 처리 환경을 통해 이를 효과적으로 관리할 수 있습니다.

- Spark의 fault-tolerance, scalability 및 병렬 처리 능력은 본 프로젝트의 안정적인 운영을 보장합니다.

## 📌 Google Cloud Storage (GCS)
- GCS는 GCP에서 제공하는 오브젝트 스토리지로, 확장성 높고 비용 효율적이며 신뢰성 있는 데이터 저장소입니다.

- 본 프로젝트에서는 Kafka로부터 수신한 Raw 데이터 원본과 Spark 처리 후의 데이터 저장용으로 활용합니다.

- 데이터 레이크(Data Lake) 역할로, 향후 추가 분석이나 백업 용도로 활용할 수 있는 환경을 제공합니다.

## 📌 BigQuery
- GCP의 서버리스 데이터 웨어하우스(DWH)로, Spark에서 처리 완료된 데이터를 테이블 형태로 저장하여 쉽게 분석할 수 있습니다.

- 대용량 데이터에 대한 빠른 쿼리 처리가 가능하며, 프로젝트에서 요구하는 시계열 데이터 분석과 집계에 최적화되어 있습니다.

- 추후 Machine Learning 또는 고급 분석 파이프라인과의 연계성이 뛰어납니다.

## 📌 Looker Studio
- BigQuery에 저장된 데이터를 시각화하고, 분석 결과를 직관적으로 표현하는 BI 도구입니다.

- 데이터의 시각적 표현을 통해 비즈니스 분석, 트렌드 탐지, 이상 데이터 식별 등을 효과적으로 지원합니다.

- 사용자가 직접 데이터 시각화를 생성·관리할 수 있어 분석 효율성과 접근성을 높일 수 있습니다.

